{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention module golden model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from golden_model import AttentionModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6967, 0.3495, 0.6867, 0.9485],\n",
      "        [0.1650, 0.2222, 0.9522, 0.8134],\n",
      "        [0.9100, 0.5385, 0.3823, 0.8618],\n",
      "        [0.9457, 0.9979, 0.8915, 0.4255],\n",
      "        [0.0727, 0.8653, 0.6557, 0.4207],\n",
      "        [0.5359, 0.7937, 0.9122, 0.1057],\n",
      "        [0.3248, 0.0791, 0.8580, 0.9853],\n",
      "        [0.7351, 0.6106, 0.2567, 0.1358]])\n",
      "tensor([[0.7527, 0.0226, 0.4261, 0.0482],\n",
      "        [0.1117, 0.6792, 0.8845, 0.1269],\n",
      "        [0.3165, 0.9162, 0.2062, 0.0437],\n",
      "        [0.2115, 0.2096, 0.9432, 0.3832],\n",
      "        [0.3239, 0.8577, 0.2060, 0.2139],\n",
      "        [0.7957, 0.9314, 0.9457, 0.6553],\n",
      "        [0.1274, 0.8892, 0.7027, 0.1668],\n",
      "        [0.0715, 0.6881, 0.5510, 0.0402]])\n",
      "tensor([[0.9066, 0.3466, 0.5183, 0.2468],\n",
      "        [0.7190, 0.9354, 0.7528, 0.3610],\n",
      "        [0.6260, 0.9892, 0.6463, 0.5128],\n",
      "        [0.5988, 0.4278, 0.2862, 0.2730],\n",
      "        [0.8817, 0.9981, 0.9600, 0.7173],\n",
      "        [0.8447, 0.5732, 0.4521, 0.1180],\n",
      "        [0.2706, 0.5099, 0.6242, 0.8518],\n",
      "        [0.6449, 0.4259, 0.0524, 0.8237]])\n",
      "tensor([[0.7150, 0.6253, 0.5173, 0.3922],\n",
      "        [0.6918, 0.6242, 0.5113, 0.4171],\n",
      "        [0.7216, 0.6376, 0.5296, 0.3995],\n",
      "        [0.7133, 0.6419, 0.5284, 0.3985],\n",
      "        [0.6798, 0.6586, 0.5375, 0.4648],\n",
      "        [0.6915, 0.6470, 0.5310, 0.4386],\n",
      "        [0.7014, 0.6170, 0.5079, 0.4016],\n",
      "        [0.7032, 0.6566, 0.5440, 0.4512]])\n",
      "tensor([[0.0900, 0.1069, 0.0777, 0.1291, 0.0899, 0.3236, 0.1066, 0.0764],\n",
      "        [0.0784, 0.1345, 0.0719, 0.1605, 0.0816, 0.2595, 0.1228, 0.0908],\n",
      "        [0.0940, 0.0953, 0.0936, 0.1033, 0.1058, 0.3282, 0.1045, 0.0754],\n",
      "        [0.0674, 0.1101, 0.0892, 0.0890, 0.0911, 0.3575, 0.1192, 0.0765],\n",
      "        [0.0581, 0.1366, 0.1053, 0.1061, 0.1076, 0.2321, 0.1480, 0.1063],\n",
      "        [0.0733, 0.1341, 0.0964, 0.1056, 0.0941, 0.2642, 0.1359, 0.0966],\n",
      "        [0.0896, 0.1227, 0.0688, 0.1653, 0.0812, 0.2773, 0.1116, 0.0836],\n",
      "        [0.1036, 0.1098, 0.1225, 0.0932, 0.1216, 0.2310, 0.1211, 0.0972]])\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 4\n",
    "seq_length = 8\n",
    "\n",
    "query = torch.rand(seq_length, embed_dim)\n",
    "key = torch.rand(seq_length, embed_dim)\n",
    "value = torch.rand(seq_length, embed_dim)\n",
    "\n",
    "atten_compute = AttentionModule()\n",
    "\n",
    "attn_output, attn_weights = atten_compute.Attention(query, key, value)\n",
    "\n",
    "print(query)\n",
    "print(key)\n",
    "print(value)\n",
    "\n",
    "\n",
    "print( attn_output )\n",
    "print( attn_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
